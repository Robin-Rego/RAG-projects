{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhQnijKu9/mlmFOzg2zD1b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Robin-Rego/RAG-projects/blob/main/Chunking_Strategies.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Context Window:**\n",
        "> The max number osf tokens that a LLM can process in a single request is known as context length"
      ],
      "metadata": {
        "id": "DCF_TqyW_dw-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A. Smaller Chunks vs Larger Chunks**"
      ],
      "metadata": {
        "id": "LORl4hwh_wqq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vz4tqSLa_V4T",
        "outputId": "f0cfba54-f12e-4eb5-8b6a-8ec9a0466dc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Using cached langchain-1.2.10-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting langchain-core<2.0.0,>=1.2.10 (from langchain)\n",
            "  Using cached langchain_core-1.2.11-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting langgraph<1.1.0,>=1.0.8 (from langchain)\n",
            "  Using cached langgraph-1.0.8-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
            "  Using cached pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
            "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core<2.0.0,>=1.2.10->langchain)\n",
            "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core<2.0.0,>=1.2.10->langchain)\n",
            "  Using cached langsmith-0.7.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting packaging>=23.2.0 (from langchain-core<2.0.0,>=1.2.10->langchain)\n",
            "  Using cached packaging-26.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pyyaml<7.0.0,>=5.3.0 (from langchain-core<2.0.0,>=1.2.10->langchain)\n",
            "  Using cached pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<2.0.0,>=1.2.10->langchain)\n",
            "  Using cached tenacity-9.1.4-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting typing-extensions<5.0.0,>=4.7.0 (from langchain-core<2.0.0,>=1.2.10->langchain)\n",
            "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting uuid-utils<1.0,>=0.12.0 (from langchain-core<2.0.0,>=1.2.10->langchain)\n",
            "  Using cached uuid_utils-0.14.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting langgraph-checkpoint<5.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.8->langchain)\n",
            "  Using cached langgraph_checkpoint-4.0.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.7 (from langgraph<1.1.0,>=1.0.8->langchain)\n",
            "  Using cached langgraph_prebuilt-1.0.7-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting langgraph-sdk<0.4.0,>=0.3.0 (from langgraph<1.1.0,>=1.0.8->langchain)\n",
            "  Using cached langgraph_sdk-0.3.5-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting xxhash>=3.5.0 (from langgraph<1.1.0,>=1.0.8->langchain)\n",
            "  Using cached xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.41.5 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
            "  Using cached pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspection>=0.4.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
            "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.10->langchain)\n",
            "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.8->langchain)\n",
            "  Using cached ormsgpack-1.12.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting httpx>=0.25.2 (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.8->langchain)\n",
            "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting orjson>=3.10.1 (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.8->langchain)\n",
            "  Using cached orjson-3.11.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
            "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain)\n",
            "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting requests>=2.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain)\n",
            "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain)\n",
            "  Using cached zstandard-0.25.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting anyio (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.8->langchain)\n",
            "  Using cached anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting certifi (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.8->langchain)\n",
            "  Using cached certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting httpcore==1.* (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.8->langchain)\n",
            "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting idna (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.8->langchain)\n",
            "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.8->langchain)\n",
            "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain)\n",
            "  Using cached charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain)\n",
            "  Using cached urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
            "Using cached langchain-1.2.10-py3-none-any.whl (111 kB)\n",
            "Using cached langchain_core-1.2.11-py3-none-any.whl (500 kB)\n",
            "Using cached langgraph-1.0.8-py3-none-any.whl (158 kB)\n",
            "Using cached pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
            "Using cached pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Using cached langgraph_checkpoint-4.0.0-py3-none-any.whl (46 kB)\n",
            "Using cached langgraph_prebuilt-1.0.7-py3-none-any.whl (35 kB)\n",
            "Using cached langgraph_sdk-0.3.5-py3-none-any.whl (70 kB)\n",
            "Using cached langsmith-0.7.1-py3-none-any.whl (322 kB)\n",
            "Using cached packaging-26.0-py3-none-any.whl (74 kB)\n",
            "Using cached pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (807 kB)\n",
            "Using cached tenacity-9.1.4-py3-none-any.whl (28 kB)\n",
            "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
            "Using cached uuid_utils-0.14.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "Using cached xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
            "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Using cached orjson-3.11.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (133 kB)\n",
            "Using cached ormsgpack-1.12.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "Using cached zstandard-0.25.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.5 MB)\n",
            "Using cached certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
            "Using cached charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
            "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
            "Using cached urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
            "Using cached anyio-4.12.1-py3-none-any.whl (113 kB)\n",
            "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: zstandard, xxhash, uuid-utils, urllib3, typing-extensions, tenacity, pyyaml, packaging, ormsgpack, orjson, jsonpointer, idna, h11, charset_normalizer, certifi, annotated-types, typing-inspection, requests, pydantic-core, jsonpatch, httpcore, anyio, requests-toolbelt, pydantic, httpx, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph, langchain\n",
            "  Attempting uninstall: zstandard\n",
            "    Found existing installation: zstandard 0.25.0\n",
            "    Uninstalling zstandard-0.25.0:\n",
            "      Successfully uninstalled zstandard-0.25.0\n",
            "  Attempting uninstall: xxhash\n",
            "    Found existing installation: xxhash 3.6.0\n",
            "    Uninstalling xxhash-3.6.0:\n",
            "      Successfully uninstalled xxhash-3.6.0\n",
            "  Attempting uninstall: uuid-utils\n",
            "    Found existing installation: uuid_utils 0.14.0\n",
            "    Uninstalling uuid_utils-0.14.0:\n",
            "      Successfully uninstalled uuid_utils-0.14.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.6.3\n",
            "    Uninstalling urllib3-2.6.3:\n",
            "      Successfully uninstalled urllib3-2.6.3\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.15.0\n",
            "    Uninstalling typing_extensions-4.15.0:\n",
            "      Successfully uninstalled typing_extensions-4.15.0\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.1.4\n",
            "    Uninstalling tenacity-9.1.4:\n",
            "      Successfully uninstalled tenacity-9.1.4\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.3\n",
            "    Uninstalling PyYAML-6.0.3:\n",
            "      Successfully uninstalled PyYAML-6.0.3\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 26.0\n",
            "    Uninstalling packaging-26.0:\n",
            "      Successfully uninstalled packaging-26.0\n",
            "  Attempting uninstall: ormsgpack\n",
            "    Found existing installation: ormsgpack 1.12.2\n",
            "    Uninstalling ormsgpack-1.12.2:\n",
            "      Successfully uninstalled ormsgpack-1.12.2\n",
            "  Attempting uninstall: orjson\n",
            "    Found existing installation: orjson 3.11.7\n",
            "    Uninstalling orjson-3.11.7:\n",
            "      Successfully uninstalled orjson-3.11.7\n",
            "  Attempting uninstall: jsonpointer\n",
            "    Found existing installation: jsonpointer 3.0.0\n",
            "    Uninstalling jsonpointer-3.0.0:\n",
            "      Successfully uninstalled jsonpointer-3.0.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.11\n",
            "    Uninstalling idna-3.11:\n",
            "      Successfully uninstalled idna-3.11\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.16.0\n",
            "    Uninstalling h11-0.16.0:\n",
            "      Successfully uninstalled h11-0.16.0\n",
            "  Attempting uninstall: charset_normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.4\n",
            "    Uninstalling charset-normalizer-3.4.4:\n",
            "      Successfully uninstalled charset-normalizer-3.4.4\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2026.1.4\n",
            "    Uninstalling certifi-2026.1.4:\n",
            "      Successfully uninstalled certifi-2026.1.4\n",
            "  Attempting uninstall: annotated-types\n",
            "    Found existing installation: annotated-types 0.7.0\n",
            "    Uninstalling annotated-types-0.7.0:\n",
            "      Successfully uninstalled annotated-types-0.7.0\n",
            "  Attempting uninstall: typing-inspection\n",
            "    Found existing installation: typing-inspection 0.4.2\n",
            "    Uninstalling typing-inspection-0.4.2:\n",
            "      Successfully uninstalled typing-inspection-0.4.2\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.5\n",
            "    Uninstalling requests-2.32.5:\n",
            "      Successfully uninstalled requests-2.32.5\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.41.5\n",
            "    Uninstalling pydantic_core-2.41.5:\n",
            "      Successfully uninstalled pydantic_core-2.41.5\n",
            "  Attempting uninstall: jsonpatch\n",
            "    Found existing installation: jsonpatch 1.33\n",
            "    Uninstalling jsonpatch-1.33:\n",
            "      Successfully uninstalled jsonpatch-1.33\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.9\n",
            "    Uninstalling httpcore-1.0.9:\n",
            "      Successfully uninstalled httpcore-1.0.9\n",
            "  Attempting uninstall: anyio\n",
            "    Found existing installation: anyio 4.12.1\n",
            "    Uninstalling anyio-4.12.1:\n",
            "      Successfully uninstalled anyio-4.12.1\n",
            "  Attempting uninstall: requests-toolbelt\n",
            "    Found existing installation: requests-toolbelt 1.0.0\n",
            "    Uninstalling requests-toolbelt-1.0.0:\n",
            "      Successfully uninstalled requests-toolbelt-1.0.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.12.5\n",
            "    Uninstalling pydantic-2.12.5:\n",
            "      Successfully uninstalled pydantic-2.12.5\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.7.1\n",
            "    Uninstalling langsmith-0.7.1:\n",
            "      Successfully uninstalled langsmith-0.7.1\n",
            "  Attempting uninstall: langgraph-sdk\n",
            "    Found existing installation: langgraph-sdk 0.3.5\n",
            "    Uninstalling langgraph-sdk-0.3.5:\n",
            "      Successfully uninstalled langgraph-sdk-0.3.5\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.2.11\n",
            "    Uninstalling langchain-core-1.2.11:\n",
            "      Successfully uninstalled langchain-core-1.2.11\n",
            "  Attempting uninstall: langgraph-checkpoint\n",
            "    Found existing installation: langgraph-checkpoint 4.0.0\n",
            "    Uninstalling langgraph-checkpoint-4.0.0:\n",
            "      Successfully uninstalled langgraph-checkpoint-4.0.0\n",
            "  Attempting uninstall: langgraph-prebuilt\n",
            "    Found existing installation: langgraph-prebuilt 1.0.7\n",
            "    Uninstalling langgraph-prebuilt-1.0.7:\n",
            "      Successfully uninstalled langgraph-prebuilt-1.0.7\n",
            "  Attempting uninstall: langgraph\n",
            "    Found existing installation: langgraph 1.0.8\n",
            "    Uninstalling langgraph-1.0.8:\n",
            "      Successfully uninstalled langgraph-1.0.8\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 1.2.10\n",
            "    Uninstalling langchain-1.2.10:\n",
            "      Successfully uninstalled langchain-1.2.10\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "gradio 5.50.0 requires pydantic<=2.12.3,>=2.0, but you have pydantic 2.12.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed annotated-types-0.7.0 anyio-4.12.1 certifi-2026.1.4 charset_normalizer-3.4.4 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.11 jsonpatch-1.33 jsonpointer-3.0.0 langchain-1.2.10 langchain-core-1.2.11 langgraph-1.0.8 langgraph-checkpoint-4.0.0 langgraph-prebuilt-1.0.7 langgraph-sdk-0.3.5 langsmith-0.7.1 orjson-3.11.7 ormsgpack-1.12.2 packaging-26.0 pydantic-2.12.5 pydantic-core-2.41.5 pyyaml-6.0.3 requests-2.32.5 requests-toolbelt-1.0.0 tenacity-9.1.4 typing-extensions-4.15.0 typing-inspection-0.4.2 urllib3-2.6.3 uuid-utils-0.14.0 xxhash-3.6.0 zstandard-0.25.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "packaging"
                ]
              },
              "id": "56ccc5d922c449a8aaf1533d5f979cd4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain.text_splitter'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2935005414.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install --upgrade --force-reinstall langchain'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_splitter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRecursiveCharacterTextSplitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorstores\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChroma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHuggingFaceEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain.text_splitter'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall langchain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import HuggingFaceEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "s3lhxPJgAJoD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}